{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting number of the mutual friends\n",
    "\n",
    "For each user having ID in the column userId count the amount of his / her common friends with each other user having ID in the column userId.\n",
    "\n",
    "Print 49 pairs of the users having the largest amount of common friends, ordered in descending order first by the common friends count , then by id of user1 and finally by id of user 2. The format is following: \"count user1 user2\"7\n",
    "\n",
    "Example:\n",
    "\n",
    "234 54719 767867\n",
    "\n",
    "120 54719 767866\n",
    "\n",
    "97 50787 327676\n",
    "\n",
    "To solve this task use the algorithm described in the last video of lesson 1. The overall plan could look like this:\n",
    "\n",
    "1. Create a new column “friend” by exploding of column “friends” (like in the demo iPython notebook)\n",
    "2. group the resulting dataframe by the column “friend” (like in the demo iPython notebook)\n",
    "3. create a column “users” by collecting all users with the same id in the column “friend” together (like in the demo iPython notebook)\n",
    "4. sort the elements in the column “users” by the function sort_array\n",
    "5. filter only the rows which have more than 1 element in the column “users”\n",
    "6. for each row emit all possible ordered pairs of users from the column “users” (tip: write a user defined function for this)\n",
    "7. count the number of times each pair has appeared\n",
    "8. with the help of the window function (like in the demo python notebook) select 49 pairs of users who have the biggest amount of common friends\n",
    "The sample dataset is located at /data/graphDFSample.\n",
    "\n",
    "The part of the result on the sample dataset:\n",
    "\n",
    "...\n",
    "3044 21864412 51640390\n",
    "3021 17139850 51640390\n",
    "3010 14985079 51640390\n",
    "2970 17139850 21864412\n",
    "2913 20158643 27967558\n",
    "...\n",
    "\n",
    "Notes\n",
    "\n",
    "The system grades standard output and error streams from the last non-empty cell. If you have clicked \"Open tool\" and received \"404\" or \"405\" error, please reload the page from the Coursera interface.\n",
    "\n",
    "If you want to deploy the environment on your own machine, please use bigdatateam/spark-course2 Docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, collect_list, size, col, row_number, sort_array,udf, count, desc\n",
    "from pyspark.sql import Window, types\n",
    "from itertools import combinations\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphPath = \"/data/graphDFSample\"\n",
    "spark_session = SparkSession.builder.enableHiveSupport().master(\"yarn\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a new column “friend” by exploding of column “friends” (like in the demo iPython notebook)\n",
    "# 2. group the resulting dataframe by the column “friend” (like in the demo iPython notebook)\n",
    "# 3. create a column “users” by collecting all users with the same id in the column “friend” together (like in the demo iPython notebook)\n",
    "# 4. sort the elements in the column “users” by the function sort_array\n",
    "# 5. filter only the rows which have more than 1 element in the column “users”\n",
    "\n",
    "reversedGraph = (\n",
    "    spark_session.read.parquet(graphPath)\n",
    "    .withColumn(\"friend\", explode('friends'))\n",
    "    .groupBy(\"friend\")\n",
    "    .agg(collect_list(\"user\").alias(\"users\"))\n",
    "    .withColumn(\"users\", sort_array('users'))\n",
    "    .where(size('users') > '1')\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- friend: integer (nullable = true)\n",
      " |-- users: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reversedGraph.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. for each row emit all possible ordered pairs of users from the column “users” (tip: write a user defined function for this)\n",
    "\n",
    "def combinatorix_pairs(users):\n",
    "    return combinations(sorted(users), 2)\n",
    "\n",
    "pair_schema = types.StructType([\n",
    "    types.StructField(\"frnd1\", types.IntegerType(), False),\n",
    "    types.StructField(\"frnd2\", types.IntegerType(), False)\n",
    "])\n",
    "\n",
    "udf_combinatorix_pairs = udf(combinatorix_pairs, types.ArrayType(pair_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. count the number of times each pair has appeared\n",
    "pair_counts = (reversedGraph.withColumn(\"pairs\", udf_combinatorix_pairs('users'))\n",
    "         .withColumn(\"pair\", explode('pairs'))\n",
    "         .groupBy(\"pair\")\n",
    "         .agg(count(\"pair\").alias(\"pair_count\"))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3206 27967558 42973992\n",
      "3130 20158643 42973992\n",
      "3066 22582764 42973992\n",
      "3044 21864412 51640390\n",
      "3021 17139850 51640390\n",
      "3010 14985079 51640390\n",
      "2970 17139850 21864412\n",
      "2913 20158643 27967558\n",
      "2903 22280814 51151280\n",
      "2870 23848749 51640390\n",
      "2855 20158643 22582764\n",
      "2849 20158643 44996025\n",
      "2846 22280814 42973992\n",
      "2784 21864412 23848749\n",
      "2779 31964081 51640390\n",
      "2776 39205988 51640390\n",
      "2754 17139850 23848749\n",
      "2749 22582764 27967558\n",
      "2728 50561859 51640390\n",
      "2724 15485897 51640390\n",
      "2700 28135661 42973992\n",
      "2655 22280814 27967558\n",
      "2653 42973992 43548989\n",
      "2639 26755857 51640390\n",
      "2621 14635589 51640390\n",
      "2608 15485897 17139850\n",
      "2606 17139850 26755857\n",
      "2601 21864412 39205988\n",
      "2600 8406745 51640390\n",
      "2599 37735419 51640390\n",
      "2597 20158643 28135661\n",
      "2585 40003405 42973992\n",
      "2585 21864412 31964081\n",
      "2581 27967558 43548989\n",
      "2579 23848749 31964081\n",
      "2578 27967558 28135661\n",
      "2578 15485897 21864412\n",
      "2577 42973992 64755069\n",
      "2574 51151280 57077210\n",
      "2573 20158643 43548989\n",
      "2566 21864412 26755857\n",
      "2564 22280814 64755069\n",
      "2561 42973992 44996025\n",
      "2556 17139850 39205988\n",
      "2543 23848749 39205988\n",
      "2521 17139850 31964081\n",
      "2515 27967558 44996025\n",
      "2506 41629539 51640390\n",
      "2505 51151280 64755069\n"
     ]
    }
   ],
   "source": [
    "# with the help of the window function (like in the demo python notebook), select 49 pairs of users who have the biggest amount of common friends\n",
    "final_results = (pair_counts.select(col(\"pair_count\"), \"pair.*\")\n",
    "           .orderBy(desc(\"pair_count\"), desc(\"frnd1\"), desc(\"frnd2\"))\n",
    "           .limit(49)\n",
    "          ).collect()\n",
    "\n",
    "for pair, frnd1, frnd2 in final_results:\n",
    "    print(\"{} {} {}\".format(pair, frnd1, frnd2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = Window.orderBy(col(\"users_size\").desc())\n",
    "    \n",
    "# top50 = reversedGraph.withColumn(\"row_number\", row_number().over(window)) \\\n",
    "#             .filter(col(\"row_number\") < 50) \\\n",
    "#             .select(col(\"friend\"), col(\"users_size\")) \\\n",
    "#             .orderBy(col(\"users_size\").desc()) \\\n",
    "#             .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark_session.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final notice:\n",
    "\n",
    "1. Please take into account that you must __not__ redirect __stderr__ to anywhere. Hadoop, Hive, and Spark print their logs to stderr and the Grading system also reads and analyses it.\n",
    "\n",
    "1. During checking the code from the notebook, the system runs all notebook's cells and reads the output of only the last filled cell. It is clear that any exception should not be thrown in the running cells. If you decide to write some text in a cell, you should change the style of the cell to Markdown (Cell -> Cell type -> Markdown).\n",
    "\n",
    "1. The Grader takes into account the output from the sample dataset you have in the notebook. Therefore, you have to \"Run All\" cells in the notebook before you send the ipynb solution.\n",
    "\n",
    "1. The name of the notebook must contain only Roman letters, numbers and characters “-” or “_”. For example, Windows adds something like \" (2)\" (with the leading space) at the end of a filename if you try to download a file with the same name. This is a problem, because you will have a space character and curly braces \"(\" and \")\". "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
