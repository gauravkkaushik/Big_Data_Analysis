{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile query_test.hql\n",
    "\n",
    "# use stackoverflow_; \n",
    "# show tables;\n",
    "\n",
    "# describe posts_sample_external;\n",
    "\n",
    "# select * from posts_sample_external limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !hive -f query_test.hql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hive_query_week2_task2_dml.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile hive_query_week2_task2_dml.hql\n",
    "\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar;\n",
    "\n",
    "USE stackoverflow_;\n",
    "\n",
    "WITH year_tag_dist AS (\n",
    "    SELECT year, exploded_tags, COUNT(*) AS cnt\n",
    "    FROM posts\n",
    "    --FROM posts_sample_external\n",
    "    LATERAL VIEW explode(tags) tagsTable AS exploded_tags\n",
    "    WHERE post_type_id = 1 AND year IN (2009, 2016)\n",
    "    GROUP BY year, exploded_tags\n",
    ")\n",
    "\n",
    "SELECT concat_ws(\"\\t\", exploded_tags, string(rank_in_2016), string(rank_in_2009), string(cntags_in_2016), string(cntags_in_2009))\n",
    "FROM (\n",
    "    SELECT\n",
    "        tags_in_2016.exploded_tags AS exploded_tags\n",
    "        ,tags_in_2016.rank AS rank_in_2016\n",
    "        ,tags_in_2009.rank AS rank_in_2009\n",
    "        ,tags_in_2016.cnt AS cntags_in_2016\n",
    "        ,tags_in_2009.cnt AS cntags_in_2009\n",
    "    FROM (\n",
    "        SELECT exploded_tags, cnt, RANK() OVER (ORDER BY cnt DESC) rank\n",
    "        FROM year_tag_dist\n",
    "        WHERE year = 2016\n",
    "        LIMIT 10\n",
    "    ) tags_in_2016\n",
    "    LEFT OUTER JOIN (\n",
    "        SELECT exploded_tags, cnt, RANK() OVER (ORDER BY cnt DESC) rank\n",
    "        FROM year_tag_dist\n",
    "        WHERE year = 2009\n",
    "    ) tags_in_2009\n",
    "    ON tags_in_2016.exploded_tags = tags_in_2009.exploded_tags\n",
    "    ORDER BY rank_in_2016\n",
    ") t_top;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-2.3.6-bin/lib/hive-common-2.3.6.jar!/hive-log4j2.properties Async: true\n",
      "Added [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar] to class path\n",
      "Added resources: [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar]\n",
      "OK\n",
      "Time taken: 0.77 seconds\n",
      "WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.\n",
      "Query ID = jovyan_20201225181236_b8e551ee-e613-408b-adc7-ddcbd8a497c5\n",
      "Total jobs = 8\n",
      "Launching Job 1 out of 8\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1608918779705_0001, Tracking URL = http://172.17.0.33:8088/proxy/application_1608918779705_0001/\n",
      "Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1608918779705_0001\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2020-12-25 18:12:47,334 Stage-1 map = 0%,  reduce = 0%\n",
      "2020-12-25 18:12:52,454 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.93 sec\n",
      "2020-12-25 18:12:57,551 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.58 sec\n",
      "MapReduce Total cumulative CPU time: 4 seconds 580 msec\n",
      "Ended Job = job_1608918779705_0001\n",
      "Launching Job 2 out of 8\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1608918779705_0002, Tracking URL = http://172.17.0.33:8088/proxy/application_1608918779705_0002/\n",
      "Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1608918779705_0002\n",
      "Hadoop job information for Stage-6: number of mappers: 1; number of reducers: 1\n",
      "2020-12-25 18:13:09,414 Stage-6 map = 0%,  reduce = 0%\n",
      "2020-12-25 18:13:14,516 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 2.56 sec\n",
      "2020-12-25 18:13:19,599 Stage-6 map = 100%,  reduce = 100%, Cumulative CPU 3.86 sec\n",
      "MapReduce Total cumulative CPU time: 3 seconds 860 msec\n",
      "Ended Job = job_1608918779705_0002\n",
      "Launching Job 3 out of 8\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1608918779705_0003, Tracking URL = http://172.17.0.33:8088/proxy/application_1608918779705_0003/\n",
      "Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1608918779705_0003\n",
      "Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "2020-12-25 18:13:30,955 Stage-2 map = 0%,  reduce = 0%\n",
      "2020-12-25 18:13:35,029 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.39 sec\n",
      "2020-12-25 18:13:40,125 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 2.51 sec\n",
      "MapReduce Total cumulative CPU time: 2 seconds 510 msec\n",
      "Ended Job = job_1608918779705_0003\n",
      "Launching Job 4 out of 8\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1608918779705_0004, Tracking URL = http://172.17.0.33:8088/proxy/application_1608918779705_0004/\n",
      "Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1608918779705_0004\n",
      "Hadoop job information for Stage-7: number of mappers: 1; number of reducers: 1\n",
      "2020-12-25 18:13:50,445 Stage-7 map = 0%,  reduce = 0%\n",
      "2020-12-25 18:13:55,553 Stage-7 map = 100%,  reduce = 0%, Cumulative CPU 1.23 sec\n",
      "2020-12-25 18:13:59,626 Stage-7 map = 100%,  reduce = 100%, Cumulative CPU 2.4 sec\n",
      "MapReduce Total cumulative CPU time: 2 seconds 400 msec\n",
      "Ended Job = job_1608918779705_0004\n",
      "Launching Job 5 out of 8\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1608918779705_0005, Tracking URL = http://172.17.0.33:8088/proxy/application_1608918779705_0005/\n",
      "Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1608918779705_0005\n",
      "Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1\n",
      "2020-12-25 18:14:10,762 Stage-3 map = 0%,  reduce = 0%\n",
      "2020-12-25 18:14:14,831 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 0.93 sec\n",
      "2020-12-25 18:14:19,907 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 2.0 sec\n",
      "MapReduce Total cumulative CPU time: 2 seconds 0 msec\n",
      "Ended Job = job_1608918779705_0005\n",
      "Stage-10 is selected by condition resolver.\n",
      "Stage-4 is filtered out by condition resolver.\n",
      "2020-12-25 18:14:25\tStarting to launch local task to process map join;\tmaximum memory = 477626368\n",
      "2020-12-25 18:14:26\tDump the side-table for tag: 1 with group count: 2369 into file: file:/tmp/jovyan/f7e4b062-6bfb-4120-9f29-7bb5668b8c24/hive_2020-12-25_18-12-36_318_3585159323175483331-1/-local-10009/HashTable-Stage-8/MapJoin-mapfile01--.hashtable\n",
      "2020-12-25 18:14:26\tUploaded 1 File to: file:/tmp/jovyan/f7e4b062-6bfb-4120-9f29-7bb5668b8c24/hive_2020-12-25_18-12-36_318_3585159323175483331-1/-local-10009/HashTable-Stage-8/MapJoin-mapfile01--.hashtable (76823 bytes)\n",
      "2020-12-25 18:14:26\tEnd of local task; Time Taken: 0.782 sec.\n",
      "Execution completed successfully\n",
      "MapredLocal task succeeded\n",
      "Launching Job 7 out of 8\n",
      "Number of reduce tasks is set to 0 since there's no reduce operator\n",
      "Starting Job = job_1608918779705_0006, Tracking URL = http://172.17.0.33:8088/proxy/application_1608918779705_0006/\n",
      "Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1608918779705_0006\n",
      "Hadoop job information for Stage-8: number of mappers: 1; number of reducers: 0\n",
      "2020-12-25 18:14:34,662 Stage-8 map = 0%,  reduce = 0%\n",
      "2020-12-25 18:14:38,732 Stage-8 map = 100%,  reduce = 0%, Cumulative CPU 1.09 sec\n",
      "MapReduce Total cumulative CPU time: 1 seconds 90 msec\n",
      "Ended Job = job_1608918779705_0006\n",
      "Launching Job 8 out of 8\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1608918779705_0007, Tracking URL = http://172.17.0.33:8088/proxy/application_1608918779705_0007/\n",
      "Kill Command = /usr/local/hadoop/bin/hadoop job  -kill job_1608918779705_0007\n",
      "Hadoop job information for Stage-5: number of mappers: 1; number of reducers: 1\n",
      "2020-12-25 18:14:49,839 Stage-5 map = 0%,  reduce = 0%\n",
      "2020-12-25 18:14:53,930 Stage-5 map = 100%,  reduce = 0%, Cumulative CPU 0.87 sec\n",
      "2020-12-25 18:14:59,082 Stage-5 map = 100%,  reduce = 100%, Cumulative CPU 2.38 sec\n",
      "MapReduce Total cumulative CPU time: 2 seconds 380 msec\n",
      "Ended Job = job_1608918779705_0007\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.58 sec   HDFS Read: 857883 HDFS Write: 283234 SUCCESS\n",
      "Stage-Stage-6: Map: 1  Reduce: 1   Cumulative CPU: 3.86 sec   HDFS Read: 166168 HDFS Write: 67863 SUCCESS\n",
      "Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 2.51 sec   HDFS Read: 290236 HDFS Write: 364 SUCCESS\n",
      "Stage-Stage-7: Map: 1  Reduce: 1   Cumulative CPU: 2.4 sec   HDFS Read: 74741 HDFS Write: 74637 SUCCESS\n",
      "Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 2.0 sec   HDFS Read: 5324 HDFS Write: 364 SUCCESS\n",
      "Stage-Stage-8: Map: 1   Cumulative CPU: 1.09 sec   HDFS Read: 4630 HDFS Write: 391 SUCCESS\n",
      "Stage-Stage-5: Map: 1  Reduce: 1   Cumulative CPU: 2.38 sec   HDFS Read: 7037 HDFS Write: 395 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 18 seconds 820 msec\n",
      "OK\n",
      "javascript\t1\t5\t2771\t192\r\n",
      "java\t2\t2\t2033\t243\r\n",
      "android\t3\t52\t1809\t25\r\n",
      "php\t4\t3\t1673\t215\r\n",
      "python\t5\t11\t1585\t108\r\n",
      "c#\t6\t1\t1519\t423\r\n",
      "html\t7\t14\t1212\t84\r\n",
      "jquery\t8\t8\t1167\t141\r\n",
      "ios\t9\t186\t914\t7\r\n",
      "css\t10\t20\t801\t59\r\n",
      "Time taken: 143.814 seconds, Fetched: 10 row(s)\r\n"
     ]
    }
   ],
   "source": [
    "!hive -f hive_query_week2_task2_dml.hql"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
